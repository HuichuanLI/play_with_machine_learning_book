{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.  ,  5.  ],\n",
       "       [ 6.25,  6.25],\n",
       "       [ 7.5 ,  7.5 ],\n",
       "       [10.  , 10.  ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    " \n",
    "#不太熟悉numpy的小伙伴，能够判断data的结构吗？\n",
    "#如果换成表是什么样子？\n",
    "import pandas as pd\n",
    "pd.DataFrame(data)\n",
    " \n",
    "#实现归一化\n",
    "scaler = MinMaxScaler()                             #实例化\n",
    "scaler = scaler.fit(data)                           #fit，在这里本质是生成min(x)和max(x)\n",
    "result = scaler.transform(data)                     #通过接口导出结果\n",
    "result\n",
    "\n",
    "result_ = scaler.fit_transform(data)                #训练和导出结果一步达成\n",
    " \n",
    "scaler.inverse_transform(result)                    #将归一化后的结果逆转\n",
    " \n",
    "#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中\n",
    " \n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "scaler = MinMaxScaler(feature_range=[5,10])         #依然实例化\n",
    "result = scaler.fit_transform(data)                 #fit_transform一步导出结果\n",
    "result\n",
    " \n",
    "#当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了\n",
    "#此时使用partial_fit作为训练接口\n",
    "#scaler = scaler.partial_fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'C:\\\\Users\\\\dddd\\\\Anaconda3\\\\python36.zip',\n",
       " 'C:\\\\Users\\\\dddd\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\dddd\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\dddd\\\\Anaconda3',\n",
       " 'C:\\\\Users\\\\dddd\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\site-packages',\n",
       " 'C:\\\\Users\\\\dddd\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\dddd\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\dddd\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\dddd\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\dddd\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\dddd\\\\.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path   #查看导入包的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])\n",
    " \n",
    "#归一化\n",
    "X_nor = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_nor\n",
    " \n",
    "#逆转归一化\n",
    "X_returned = X_nor * (X.max(axis=0) - X.min(axis=0)) + X.min(axis=0)\n",
    "X_returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    " \n",
    "scaler = StandardScaler()                           #实例化\n",
    "scaler.fit(data)                                    #fit，本质是生成均值和方差\n",
    " \n",
    "scaler.mean_                                        #查看均值的属性mean_\n",
    "scaler.var_                                         #查看方差的属性var_\n",
    " \n",
    "x_std = scaler.transform(data)                      #通过接口导出结果\n",
    " \n",
    "x_std.mean()                                        #导出的结果是一个数组，用mean()查看均值\n",
    "x_std.std()                                         #用std()查看方差\n",
    " \n",
    "scaler.fit_transform(data)                          #使用fit_transform(data)一步达成结果\n",
    " \n",
    "scaler.inverse_transform(x_std)                     #使用inverse_transform逆转标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked Survived\n",
       "0  22.0    male        S       No\n",
       "1  38.0  female        C      Yes\n",
       "2  26.0  female        S      Yes\n",
       "3  35.0  female        S      Yes\n",
       "4  35.0    male        S       No"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r\".\\Narrativedata.csv\"\n",
    "                   ,index_col=0\n",
    "                  )#index_col=0将第0列作为索引，不写则认为第0列为特征\n",
    " \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Age         714 non-null float64\n",
      "Sex         891 non-null object\n",
      "Embarked    889 non-null object\n",
      "Survived    891 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Age         891 non-null float64\n",
      "Sex         891 non-null object\n",
      "Embarked    889 non-null object\n",
      "Survived    891 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Age         891 non-null float64\n",
      "Sex         891 non-null object\n",
      "Embarked    891 non-null object\n",
      "Survived    891 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "#填补年龄\n",
    " \n",
    "Age = data.loc[:,\"Age\"].values.reshape(-1,1)            #sklearn当中特征矩阵必须是二维\n",
    "Age[:20]\n",
    " \n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer()                              #实例化，默认均值填补\n",
    "imp_median = SimpleImputer(strategy=\"median\")           #用中位数填补\n",
    "imp_0 = SimpleImputer(strategy=\"constant\",fill_value=0) #用0填补\n",
    " \n",
    "imp_mean = imp_mean.fit_transform(Age)                  #fit_transform一步完成调取结果\n",
    "imp_median = imp_median.fit_transform(Age)\n",
    "imp_0 = imp_0.fit_transform(Age)\n",
    " \n",
    "imp_mean[:20]\n",
    "imp_median[:20]\n",
    "imp_0[:20]\n",
    " \n",
    "#在这里我们使用中位数填补Age\n",
    "data.loc[:,\"Age\"] = imp_median\n",
    " \n",
    "data.info()\n",
    " \n",
    "#使用众数填补Embarked\n",
    "Embarked = data.loc[:,\"Embarked\"].values.reshape(-1,1)\n",
    "imp_mode = SimpleImputer(strategy = \"most_frequent\")\n",
    "data.loc[:,\"Embarked\"] = imp_mode.fit_transform(Embarked)\n",
    " \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'Unknown', 'Yes', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Unknown', 'Yes', 'Yes', 'Yes', 'No', 'Unknown', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'Unknown', 'Yes', 'No', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'Yes', 'Unknown', 'No', 'Unknown',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Unknown', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No',\n",
       "       'No', 'Unknown', 'Unknown', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'Unknown', 'No', 'Unknown', 'Unknown', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'No', 'No', 'No',\n",
       "       'Unknown', 'No', 'No', 'No', 'No', 'No', 'No', 'Unknown', 'Yes',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'Unknown',\n",
       "       'Yes', 'Yes', 'No', 'No', 'Unknown', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Unknown', 'Yes',\n",
       "       'Unknown', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'Unknown', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'Unknown', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'No', 'Unknown', 'No', 'No', 'Unknown', 'Yes', 'Yes',\n",
       "       'Unknown', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'Unknown', 'Unknown', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
       "       'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Unknown', 'Yes', 'No', 'Yes',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'Unknown', 'Yes', 'Yes', 'No', 'Unknown', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'No', 'Unknown', 'Yes', 'Yes', 'Yes', 'No', 'Unknown',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'Unknown', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Unknown', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'Unknown', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Unknown', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes',\n",
       "       'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'Yes', 'Unknown', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'Unknown', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Unknown', 'Unknown', 'No', 'Yes', 'Yes', 'No', 'No', 'Unknown',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Unknown',\n",
       "       'Yes', 'No', 'No', 'Unknown', 'No', 'No', 'Unknown', 'No', 'No',\n",
       "       'No', 'Yes', 'Unknown', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes',\n",
       "       'Unknown', 'Yes', 'Yes', 'Unknown', 'Yes', 'Yes', 'No', 'Yes',\n",
       "       'Yes', 'Unknown', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Unknown', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Unknown', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Unknown', 'Yes',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Unknown', 'No', 'Unknown', 'No',\n",
       "       'Unknown', 'Unknown', 'Yes', 'Yes', 'Unknown', 'Yes', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'No', 'Yes', 'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Unknown', 'Yes', 'Yes', 'Unknown', 'No', 'No', 'Yes', 'No', 'No',\n",
       "       'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'Unknown', 'Yes', 'Unknown', 'No', 'Unknown', 'No', 'Yes',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'Yes', 'Unknown', 'Yes', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'Unknown', 'No',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'Yes', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Yes', 'No',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Unknown', 'Yes',\n",
       "       'Yes', 'Yes', 'Yes', 'No', 'Unknown', 'No', 'Unknown', 'Unknown',\n",
       "       'Yes', 'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'Unknown', 'Unknown', 'Yes', 'No', 'Unknown', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Unknown',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'Unknown', 'No',\n",
       "       'No', 'Unknown', 'Unknown', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Unknown', 'No',\n",
       "       'Unknown', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'Unknown', 'No', 'No', 'No', 'Unknown', 'Unknown', 'No',\n",
       "       'Unknown', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'Unknown', 'Unknown', 'Unknown', 'No', 'No',\n",
       "       'Yes', 'No', 'Unknown', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'No', 'Unknown', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Unknown', 'No'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_ = pd.read_csv(r\".\\Narrativedata.csv\"\n",
    "                   ,index_col=0\n",
    "                  )#index_col=0将第0列作为索引，不写则认为第0列为特征\n",
    "\n",
    "data_.head()\n",
    " \n",
    "data_.loc[:,\"Age\"] = data_.loc[:,\"Age\"].fillna(data_.loc[:,\"Age\"].median())\n",
    "#.fillna 在DataFrame里面直接进行填补\n",
    " \n",
    "data_.dropna(axis=0,inplace=True)\n",
    "#.dropna(axis=0)删除所有有缺失值的行，.dropna(axis=1)删除所有有缺失值的列\n",
    "#参数inplace，为True表示在原数据集上进行修改，为False表示生成一个复制对象，不修改原数据，默认False\n",
    "# _data_ = data_.drop(axis=0,inplace=False)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "y = data_.iloc[:,-1]                         #要输入的是标签，不是特征矩阵，所以允许一维\n",
    " \n",
    "le = LabelEncoder()                         #实例化\n",
    "le = le.fit(y)                              #导入数据\n",
    "label = le.transform(y)                     #transform接口调取结果\n",
    " \n",
    "le.classes_                                 #属性.classes_查看标签中究竟有多少类别\n",
    "label                                       #查看获取的结果label\n",
    " \n",
    "le.fit_transform(y)                         #也可以直接fit_transform一步到位\n",
    " \n",
    "le.inverse_transform(label)                 #使用inverse_transform可以逆转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "y = data.iloc[:,-1]                         #要输入的是标签，不是特征矩阵，所以允许一维\n",
    " \n",
    "le = LabelEncoder()                         #实例化\n",
    "le = le.fit(y)                              #导入数据\n",
    "label = le.transform(y)                     #transform接口调取结果\n",
    " \n",
    "le.classes_                                 #属性.classes_查看标签中究竟有多少类别\n",
    "label                                       #查看获取的结果label\n",
    " \n",
    "le.fit_transform(y)                         #也可以直接fit_transform一步到位\n",
    " \n",
    "le.inverse_transform(label)                 #使用inverse_transform可以逆转\n",
    "\n",
    "data.iloc[:,-1] = label                     #让标签等于我们运行出来的结果\n",
    " \n",
    "data.head()\n",
    " \n",
    "#如果不需要教学展示的话我会这么写：\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data.iloc[:,-1] = LabelEncoder().fit_transform(data.iloc[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  Embarked  Survived\n",
       "0  22.0  1.0       2.0         0\n",
       "1  38.0  0.0       0.0         2\n",
       "2  26.0  0.0       2.0         2\n",
       "3  35.0  0.0       2.0         2\n",
       "4  35.0  1.0       2.0         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    " \n",
    "#接口categories_对应LabelEncoder的接口classes_，一模一样的功能\n",
    "data_ = data.copy()\n",
    " \n",
    "data_.head()\n",
    " \n",
    "OrdinalEncoder().fit(data_.iloc[:,1:-1]).categories_\n",
    " \n",
    "data_.iloc[:,1:-1] = OrdinalEncoder().fit_transform(data_.iloc[:,1:-1])\n",
    " \n",
    "data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Survived  Female  Male  Embarked_C  Embarked_Q  Embarked_S\n",
       "0  22.0         0     0.0   1.0         0.0         0.0         1.0\n",
       "1  38.0         2     1.0   0.0         1.0         0.0         0.0\n",
       "2  26.0         2     1.0   0.0         0.0         0.0         1.0\n",
       "3  35.0         2     1.0   0.0         0.0         0.0         1.0\n",
       "4  35.0         0     0.0   1.0         0.0         0.0         1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    " \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = data.iloc[:,1:-1]\n",
    " \n",
    "enc = OneHotEncoder(categories='auto').fit(X)\n",
    "result = enc.transform(X).toarray()\n",
    "result\n",
    " \n",
    "#依然可以直接一步到位，但为了给大家展示模型属性，所以还是写成了三步\n",
    "OneHotEncoder(categories='auto').fit_transform(X).toarray()\n",
    " \n",
    "#依然可以还原\n",
    "pd.DataFrame(enc.inverse_transform(result))\n",
    " \n",
    "enc.get_feature_names()#返回每一个经过哑变量后生成稀疏矩阵列的名字\n",
    " \n",
    "result\n",
    "result.shape\n",
    " \n",
    "#axis=1,表示跨行进行合并，也就是将两表左右相连，如果是axis=0，就是将量表上下相连\n",
    "newdata = pd.concat([data,pd.DataFrame(result)],axis=1)\n",
    " \n",
    "newdata.head()\n",
    " \n",
    "newdata.drop([\"Sex\",\"Embarked\"],axis=1,inplace=True)\n",
    " \n",
    "newdata.columns = [\"Age\",\"Survived\",\"Female\",\"Male\",\"Embarked_C\",\"Embarked_Q\",\"Embarked_S\"]\n",
    " \n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex Embarked  Survived\n",
       "0  0.0    male        S         0\n",
       "1  1.0  female        C         2\n",
       "2  0.0  female        S         2\n",
       "3  1.0  female        S         2\n",
       "4  1.0    male        S         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将年龄二值化\n",
    " \n",
    "data_2 = data.copy()\n",
    " \n",
    "from sklearn.preprocessing import Binarizer\n",
    "X = data_2.iloc[:,0].values.reshape(-1,1)               #类为特征专用，所以不能使用一维数组\n",
    "transformer = Binarizer(threshold=30).fit_transform(X)\n",
    " \n",
    "data_2.iloc[:,0] = transformer\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    " \n",
    "X = data.iloc[:,0].values.reshape(-1,1) \n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "est.fit_transform(X)\n",
    " \n",
    "#查看转换后分的箱：变成了一列中的三箱\n",
    "set(est.fit_transform(X).ravel())\n",
    " \n",
    "est = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')\n",
    "#查看转换后分的箱：变成了哑变量\n",
    "est.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n这个数据量相对夸张，如果使用支持向量机和神经网络，很可能会直接跑不出来。使用KNN跑一次大概需要半个小时。\\n用这个数据举例，能更够体现特征工程的重要性。\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入数据，让我们使用digit recognizor数据来一展身手\n",
    " \n",
    "import pandas as pd\n",
    "data = pd.read_csv(r\".\\digit recognizor.csv\")\n",
    " \n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n",
    " \n",
    "X.shape\n",
    " \n",
    "\"\"\"\n",
    "这个数据量相对夸张，如果使用支持向量机和神经网络，很可能会直接跑不出来。使用KNN跑一次大概需要半个小时。\n",
    "用这个数据举例，能更够体现特征工程的重要性。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>698</th>\n",
       "      <th>699</th>\n",
       "      <th>700</th>\n",
       "      <th>701</th>\n",
       "      <th>702</th>\n",
       "      <th>703</th>\n",
       "      <th>704</th>\n",
       "      <th>705</th>\n",
       "      <th>706</th>\n",
       "      <th>707</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  698  699  700  701  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   702  703  704  705  706  707  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 708 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold()                      #实例化，不填参数默认方差为0\n",
    "X_var0 = selector.fit_transform(X)                  #获取删除不合格特征之后的新特征矩阵\n",
    " \n",
    "#也可以直接写成 X = VairanceThreshold().fit_transform(X)\n",
    " \n",
    "X_var0.shape#(42000, 708)\n",
    "pd.DataFrame(X_var0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 392)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# X.var()#每一列的方差\n",
    "X_fsvar = VarianceThreshold(np.median(X.var().values)).fit_transform(X)\n",
    " \n",
    "X.var().values\n",
    " \n",
    "np.median(X.var().values)\n",
    "   \n",
    "X_fsvar.shape#(42000, 392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 685)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#若特征是伯努利随机变量，假设p=0.8，即二分类特征中某种分类占到80%以上的时候删除特征\n",
    "X_bvar = VarianceThreshold(.8 * (1 - .8)).fit_transform(X)\n",
    "X_bvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN vs 随机森林在不同方差过滤效果下的对比\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    " \n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n",
    " \n",
    "X_fsvar = VarianceThreshold(np.median(X.var().values)).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======【TIME WARNING：35mins +】======#\n",
    "cross_val_score(KNN(),X,y,cv=5).mean()\n",
    " \n",
    "#python中的魔法命令，可以直接使用%%timeit来计算运行这个cell中的代码所需的时间\n",
    "#为了计算所需的时间，需要将这个cell中的代码运行很多次（通常是7次）后求平均值，因此运行%%timeit的时间会\n",
    "# 远远超过cell中的代码单独运行的时间\n",
    " \n",
    "#======【TIME WARNING：4 hours】======#\n",
    "%%timeit\n",
    "cross_val_score(KNN(),X,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======【TIME WARNING：20 mins+】======#\n",
    "cross_val_score(KNN(),X_fsvar,y,cv=5).mean()\n",
    " \n",
    "#======【TIME WARNING：2 hours】======#\n",
    "%%timeit\n",
    "cross_val_score(KNN(),X,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(RFC(n_estimators=10,random_state=0),X,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(RFC(n_estimators=10,random_state=0),X_fsvar,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    " \n",
    "#假设在这里我一直我需要300个特征\n",
    "X_fschi = SelectKBest(chi2, k=300).fit_transform(X_fsvar, y)\n",
    "X_fschi.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======【TIME WARNING: 5 mins】======#\n",
    " \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "score = []\n",
    "for i in range(390,200,-10):\n",
    "    X_fschi = SelectKBest(chi2, k=i).fit_transform(X_fsvar, y)\n",
    "    once = cross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.plot(range(390,200,-10),score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chivalue, pvalues_chi = chi2(X_fsvar,y)\n",
    " \n",
    "chivalue\n",
    " \n",
    "pvalues_chi\n",
    " \n",
    "#k取多少？我们想要消除所有p值大于设定值，比如0.05或0.01的特征：\n",
    "k = chivalue.shape[0] - (pvalues_chi > 0.05).sum()\n",
    " \n",
    "#X_fschi = SelectKBest(chi2, k=填写具体的k).fit_transform(X_fsvar, y)\n",
    "#cross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    " \n",
    "F, pvalues_f = f_classif(X_fsvar,y)\n",
    " \n",
    "F\n",
    " \n",
    "pvalues_f\n",
    " \n",
    "k = F.shape[0] - (pvalues_f > 0.05).sum()\n",
    " \n",
    "#X_fsF = SelectKBest(f_classif, k=填写具体的k).fit_transform(X_fsvar, y)\n",
    "#cross_val_score(RFC(n_estimators=10,random_state=0),X_fsF,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    " \n",
    "result = MIC(X_fsvar,y)\n",
    " \n",
    "k = result.shape[0] - sum(result <= 0)\n",
    " \n",
    "#X_fsmic = SelectKBest(MIC, k=填写具体的k).fit_transform(X_fsvar, y)\n",
    "#cross_val_score(RFC(n_estimators=10,random_state=0),X_fsmic,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    " \n",
    "RFC_ = RFC(n_estimators =10,random_state=0)\n",
    " \n",
    "X_embedded = SelectFromModel(RFC_,threshold=0.005).fit_transform(X,y)\n",
    " \n",
    "#在这里我只想取出来有限的特征。0.005这个阈值对于有780个特征的数据来说，是非常高的阈值，因为平均每个特征\n",
    "# 只能够分到大约0.001的feature_importances_\n",
    " \n",
    "X_embedded.shape\n",
    " \n",
    "#模型的维度明显被降低了\n",
    "#同样的，我们也可以画学习曲线来找最佳阈值\n",
    " \n",
    "#======【TIME WARNING：10 mins】======#\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "RFC_.fit(X,y).feature_importances_\n",
    " \n",
    "threshold = np.linspace(0,(RFC_.fit(X,y).feature_importances_).max(),20)\n",
    " \n",
    "score = []\n",
    "for i in threshold:\n",
    "    X_embedded = SelectFromModel(RFC_,threshold=i).fit_transform(X,y)\n",
    "    once = cross_val_score(RFC_,X_embedded,y,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.plot(threshold,score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = SelectFromModel(RFC_,threshold=0.00067).fit_transform(X,y)\n",
    "X_embedded.shape\n",
    " \n",
    "cross_val_score(RFC_,X_embedded,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======【TIME WARNING：10 mins】======#\n",
    "score2 = []\n",
    "for i in np.linspace(0,0.00134,20):\n",
    "    X_embedded = SelectFromModel(RFC_,threshold=i).fit_transform(X,y)\n",
    "    once = cross_val_score(RFC_,X_embedded,y,cv=5).mean()\n",
    "    score2.append(once)\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(np.linspace(0,0.00134,20),score2)\n",
    "plt.xticks(np.linspace(0,0.00134,20))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = SelectFromModel(RFC_,threshold=0.000564).fit_transform(X,y)\n",
    "X_embedded.shape\n",
    " \n",
    "cross_val_score(RFC_,X_embedded,y,cv=5).mean()\n",
    " \n",
    "#=====【TIME WARNING：2 min】=====#\n",
    "#我们可能已经找到了现有模型下的最佳结果，如果我们调整一下随机森林的参数呢？\n",
    "cross_val_score(RFC(n_estimators=100,random_state=0),X_embedded,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "RFC_ = RFC(n_estimators =10,random_state=0)\n",
    "selector = RFE(RFC_, n_features_to_select=340, step=50).fit(X, y)\n",
    " \n",
    "selector.support_.sum()#340\n",
    " \n",
    "selector.ranking_\n",
    " \n",
    "X_wrapper = selector.transform(X)\n",
    " \n",
    "cross_val_score(RFC_,X_wrapper,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======【TIME WARNING: 15 mins】======#\n",
    " \n",
    "score = []\n",
    "for i in range(1,751,50):\n",
    "    X_wrapper = RFE(RFC_,n_features_to_select=i, step=50).fit_transform(X,y)\n",
    "    once = cross_val_score(RFC_,X_wrapper,y,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(range(1,751,50),score)\n",
    "plt.xticks(range(1,751,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
